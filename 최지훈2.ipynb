{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "최지훈2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun212/HAICON2021/blob/main/%EC%B5%9C%EC%A7%80%ED%9B%882.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBADzkv7qZPP"
      },
      "source": [
        "# 최지훈 작성\n",
        "# 이경연 작성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyEmgzcgsP4H"
      },
      "source": [
        "#최지훈 작성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c97UeQQWto4j"
      },
      "source": [
        "# 최종 모델 \n",
        "\n",
        "## 1. Model 구성 \n",
        "1. 1D CNN(1D Convolutional Neural Networks)\n",
        "2. MSE Loss + AdamW \n",
        "\n",
        "## 2. 최종 성능최적화 방법\n",
        "1. Model의 ouput에 lowpass filter를 적용해 noise를 제거 (데이터후처리)\n",
        "2. shingle size와 stride 튜닝                           (데이터전처리)\n",
        "3. epoch 튜닝                                           (모델 hyper-parameter 조정)\n",
        "4. Threshold 조정                                       (모델 hyper-parameter 조정)\n",
        "5. model selection by grid-search\n",
        "\n",
        "## 3. 모델 선정 기준\n",
        "1. 일반화 성능이 높은 모델 (Test data' TaPR과 Public score의 차이가 적은 모델)\n",
        "2. public score가 높은 모델 \n",
        "\n",
        "## 4. 최종 모델 성능\n",
        "- Test data TaPR : F1: 0.975 (TaP: 0.997, TaR: 0.953)\n",
        "- Publice score : 0.97414\n",
        "- Private score : 0.93414\n",
        "- 최종 모델 경로 : 첨부 파일의 ./final_submission/final_model_shingle40_epoch70.pt\n",
        "\n",
        "## 5. 시도한 방법론 (최종 사용X)\n",
        "\n",
        "- 모델 관점 \n",
        "    1. LSTM AutoEncoder 모델\n",
        "    2. RCF(random cut forest) 모델\n",
        "   \n",
        "   \n",
        "- 데이터 전처리관점\n",
        "    1. feature selection\n",
        "    2. data augmentation\n",
        "        - jittering \n",
        "        - reverse\n",
        "        - lstm autoencoder\n",
        "\n",
        "## 6. Path 정보\n",
        "\n",
        "- Data Path\n",
        "    1. traing data : ./hai-master/training/\n",
        "    2. validation data : ./hai-master/validation/\n",
        "    3. test data : ./hai-master/testing/\n",
        "    \n",
        "    \n",
        "- Model Path\n",
        "    1. model 저장 경로 : ./hai-master/{model_name}.pt\n",
        "    2. 최종제출 model : ./hai-master/final_model_shingle40_epoch70.pt\n",
        "    \n",
        "    \n",
        "- Submission Path\n",
        "    1. submission 저장 경로 : ./hai-master/\n",
        "    2. sample path : ./hai-master/sample_submission.csv\n",
        "    3. 최종제출 submisstion : ./hai-master/final_submission.csv\n",
        "    \n",
        "    \n",
        "- TaPR Lib path\n",
        "    1. whl file : ./eTaPR-1.12-py3-none-any.whl\n",
        "    \n",
        "## 7. Library 버전\n",
        "- toolz==0.10.0\n",
        "- torch==1.4.0\n",
        "- torchvision==0.5.0\n",
        "- torchviz==0.0.1\n",
        "- tornado==6.0.4\n",
        "- numpy==1.18.5\n",
        "- notebook==6.0.3\n",
        "- pyparsing==2.4.7\n",
        "- python 3\n",
        "- matplotlib \n",
        "- pandas\n",
        "- dateutil\n",
        "- datetime\n",
        "\n",
        "## 8. 작업환경\n",
        "- AWS sagemaker\n",
        "- instance type : ml.p2.8xlarge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaNsZaBXuPJG"
      },
      "source": [
        "## Import Library\n",
        "\n",
        "TaPR을 install하고 필요한 library들을 import 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fDkzPyEuPf6"
      },
      "source": [
        "import os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import timedelta\n",
        "import dateutil\n",
        "from tqdm import tqdm\n",
        "import easydict\n",
        "from TaPR_pkg import etapr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOUPvps8t6I4"
      },
      "source": [
        "## 데이터 전처리\n",
        "\n",
        "제공된 csv 데이터를 읽어 오는 작업을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rmxK8y0t_Yp"
      },
      "source": [
        "def dataframe_from_csv(target):\n",
        "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
        "\n",
        "def dataframe_from_csvs(targets):\n",
        "    return pd.concat([dataframe_from_csv(x) for x in targets])\n",
        "\n",
        "def normalize(df):\n",
        "    ndf = df.copy()\n",
        "    for c in df.columns:\n",
        "        if TAG_MIN[c] == TAG_MAX[c]:\n",
        "            ndf[c] = df[c] - TAG_MIN[c]\n",
        "        else:\n",
        "            ndf[c] = (df[c] - TAG_MIN[c]) / (TAG_MAX[c] - TAG_MIN[c])\n",
        "    return ndf"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
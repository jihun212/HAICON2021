{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "최지훈2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun212/HAICON2021/blob/main/%EC%B5%9C%EC%A7%80%ED%9B%882.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceB2WDvQomWW"
      },
      "source": [
        "**아래에 나오는 모든 문자열이 UTF-8 형식이라는 것을 명시하는 코드**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNesQtqsok7p"
      },
      "source": [
        "#-*- coding: utf-8 -*-"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N8X54tTbSEX"
      },
      "source": [
        "## Import Library\n",
        "\n",
        "필요한 library들을 import 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmd1AZ57bZ66"
      },
      "source": [
        "import os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import timedelta\n",
        "import dateutil\n",
        "from tqdm import tqdm\n",
        "import easydict\n",
        "from TaPR_pkg import etapr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAggTqaElCqa"
      },
      "source": [
        "## 데이터 전처리\n",
        "\n",
        "제공된 csv 데이터를 읽어 오는 작업을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbHoh53mbzOZ"
      },
      "source": [
        "def dataframe_from_csv(target):\n",
        "    return pd.read_csv(target).rename(columns=lambda x: x.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0xcjnF5bzuN"
      },
      "source": [
        "def dataframe_from_csvs(targets):\n",
        "    return pd.concat([dataframe_from_csv(x) for x in targets])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a6Rb0mdlE3x"
      },
      "source": [
        "normalize 함수는 Dataframe을 정규화합니다. 정규화 방법은 최솟값, 최댓값을 이용하여 0~1의 범위에 들어오도록 하는 것입니다.\n",
        "\n",
        "가끔 값이 전혀 변하지 않는 필드가 있습니다. 이 경우 최솟값과 최댓값이 같을 것입니다. 본 문서에서는 이런 필드를 모두 0으로 만들었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD6yt7oQbz0g"
      },
      "source": [
        "def normalize(df):\n",
        "    ndf = df.copy()\n",
        "    for c in df.columns:\n",
        "        if TAG_MIN[c] == TAG_MAX[c]:\n",
        "            ndf[c] = df[c] - TAG_MIN[c]\n",
        "        else:\n",
        "            ndf[c] = (df[c] - TAG_MIN[c]) / (TAG_MAX[c] - TAG_MIN[c])\n",
        "    return ndf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVYBdLNkmqJU"
      },
      "source": [
        "### Feature Selection\n",
        "\n",
        "각 columns 별 데이터의 분포를 시각화하여 확인합니다. 몇몇 데이터는 유의미하지 않기 때문에, 추후 feature selection을 진행해서 모델 효율성을 증진시킬 수 있었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1f96NBqmpuR"
      },
      "source": [
        "for i, v in enumerate(TEST_DF.columns.values):\n",
        "    fig= plt.figure()\n",
        "    plt.plot(TEST_DF[v])\n",
        "    MIN = TEST_DF[v].min()\n",
        "    MAX = TEST_DF[v].max()\n",
        "    plt.plot(   (TEST_DF_RAW[ATTACK_FIELD]*MAX + MIN)  )\n",
        "    fig.savefig('./data/sensor_graph_test/'+v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E60bvelMlRHP"
      },
      "source": [
        "#학습 모델 설정 & 데이터 입출력 정의\n",
        "\n",
        "딥러닝 학습과 추론에는 PyTorch를 사용했습니다.\n",
        "\n",
        "정상 데이터만 학습해야 하고, 정상 데이터에는 어떠한 label도 없으므로 unsupervised learning을 해야 합니다.\n",
        "\n",
        "\n",
        "모델의 입출력은 다음과 같이 설정했습니다.\n",
        "\n",
        "입력 : 윈도우에 해당하는 값\n",
        "\n",
        "출력 : 윈도우의 가장 마지막 초(입력+1)의 값\n",
        "\n",
        "이후 탐지 시에는 모델이 출력하는 값(예측값)과 실제로 들어온 값의 차를 보고 차이가 크면 이상으로 간주했습니다. 많은 오차가 발생한다는 것은 기존에 학습 데이터셋에서 본 적이 없는 패턴이기 때문이라는 가정입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiR055dCbz26"
      },
      "source": [
        "class HS_DATASET(Dataset):\n",
        "    def __init__(self, timestamps, df, window_size=90, stride=1, attacks=None):\n",
        "        window_given=window_size - 1\n",
        "        self.ts = np.array(timestamps)\n",
        "        self.tag_values = np.array(df, dtype=np.float32)\n",
        "        self.valid_idxs = []\n",
        "        self.window_size = window_size\n",
        "        self.window_given = window_given\n",
        "        for L in tqdm(range(len(self.ts) - self.window_size + 1)):\n",
        "            R = L + self.window_size - 1\n",
        "            if dateutil.parser.parse(self.ts[R]) - dateutil.parser.parse(\n",
        "                self.ts[L]\n",
        "            ) == timedelta(seconds=self.window_size - 1):\n",
        "                self.valid_idxs.append(L)\n",
        "        self.valid_idxs = np.array(self.valid_idxs, dtype=np.int32)[::stride]\n",
        "        self.n_idxs = len(self.valid_idxs)\n",
        "        print(f\"# of valid windows: {self.n_idxs}\")\n",
        "        if attacks is not None:\n",
        "            self.attacks = np.array(attacks, dtype=np.float32)\n",
        "            self.with_attack = True\n",
        "        else:\n",
        "            self.with_attack = False\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_idxs\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = self.valid_idxs[idx]\n",
        "        last = i + self.window_size - 1\n",
        "        item = {\"attack\": self.attacks[last]} if self.with_attack else {}\n",
        "        item[\"ts\"] = self.ts[i + self.window_size - 1]\n",
        "        item[\"given\"] = torch.from_numpy(self.tag_values[i : i + self.window_given])\n",
        "        item[\"answer\"] = torch.from_numpy(self.tag_values[last])\n",
        "        return item"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YUdty5zmRhG"
      },
      "source": [
        "# 모델 구조 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erltD-QfwpOS"
      },
      "source": [
        "**model 정의**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB4FKGmRbz5X"
      },
      "source": [
        "class model(nn.Module):\n",
        "    def __init__(self, input_size, window_size):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Conv1d(in_channels=input_size, out_channels = input_size*20, kernel_size = 13, stride = 1, groups = input_size) #1D CNN Layer\n",
        "        self.relu = nn.ReLU() #ReLU activation function\n",
        "        self.ap1 = nn.AvgPool1d(3, stride=1) #Pooling Layer\n",
        "        self.layer2 = nn.Conv1d(in_channels = input_size*20, out_channels=input_size*20*3, kernel_size = 1, stride = 1) #1D CNN Layer\n",
        "        self.fc = nn.Linear((window_size-1-12-2)*input_size*20*3, input_size) #Fully Connected Layer\n",
        "\n",
        "    def forward(self, in_x):\n",
        "        in_x = torch.transpose(in_x, 1, 2)\n",
        "        x = self.layer1(in_x) #1D CNN Layer\n",
        "        x = self.relu(x) #ReLU activation function\n",
        "        x = self.ap1(x) #Pooling Layer\n",
        "        x = self.layer2(x) #1D CNN Layer\n",
        "        x = self.relu(x) #ReLU activation function\n",
        "        x = torch.flatten(x, start_dim=1) #Flatten Layer\n",
        "        out = self.fc(x) #Fully Connected Layer\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81A4DC75xu0P"
      },
      "source": [
        "###Training을 위해 Loss function과 Metric을 선정했습니다.\n",
        "\n",
        "Loss function은 MSE를 선택했고, optimizer는 AdamW(Loshchilov & Hutter, \"Decoupled Weight Decay Regularization\", ICLR 2019)를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZPGidpMbz71"
      },
      "source": [
        "def train(dataset, model, batch_size, n_epochs):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters())\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "    epochs = tqdm(range(n_epochs), total=n_epochs, desc=\"training\")\n",
        "    best = {\"loss\": sys.float_info.max}\n",
        "    loss_history = []\n",
        "    for e in epochs:\n",
        "        epoch_loss = 0\n",
        "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"batch\"):\n",
        "            optimizer.zero_grad()\n",
        "            given = batch[\"given\"].to(args.device)\n",
        "            guess = model(given)\n",
        "            answer = batch[\"answer\"].to(args.device)\n",
        "            loss = loss_fn(answer, guess)\n",
        "            loss.backward()\n",
        "            epoch_loss += loss.item()\n",
        "            optimizer.step()\n",
        "        loss_history.append(epoch_loss)\n",
        "        epochs.set_postfix_str(f\"loss: {epoch_loss:.6f}\")\n",
        "        if epoch_loss < best[\"loss\"]:\n",
        "            best[\"state\"] = model.state_dict()\n",
        "            best[\"loss\"] = epoch_loss\n",
        "            best[\"epoch\"] = e + 1\n",
        "    return best, loss_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKmVqn6uqVBL"
      },
      "source": [
        "**inference function을 정의하고 validation dataset을 추론합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lfZsyc7bz-O"
      },
      "source": [
        "def inference(dataset, model, batch_size):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    ts, dist, att = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            given = batch[\"given\"].to(args.device)\n",
        "            answer = batch[\"answer\"].to(args.device)\n",
        "            guess = model(given)\n",
        "            ts.append(np.array(batch[\"ts\"]))\n",
        "            dist.append(torch.abs(answer - guess).cpu().numpy())\n",
        "            try:\n",
        "                att.append(np.array(batch[\"attack\"]))\n",
        "            except:\n",
        "                att.append(np.zeros(batch_size))\n",
        "    return (\n",
        "        np.concatenate(ts),\n",
        "        np.concatenate(dist),\n",
        "        np.concatenate(att),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nx8em8drOnK"
      },
      "source": [
        "모델에서 생성된 anomaly score를 시각화할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CPHzHGbb0Ai"
      },
      "source": [
        "def check_graph(xs, att, label, piece=2, THRESHOLD=None, FILENAME='result'):\n",
        "    l = xs.shape[0]\n",
        "    chunk = l // piece\n",
        "    fig, axs = plt.subplots(piece + 1, figsize=(20, 4 * piece))\n",
        "    for i in range(piece):\n",
        "        L = i * chunk\n",
        "        R = min(L + chunk, l)\n",
        "        xticks = range(L, R)\n",
        "        axs[i].plot(xticks, xs[L:R])\n",
        "        if len(xs[L:R]) > 0:\n",
        "            peak = max(xs[L:R])\n",
        "            axs[i].plot(xticks, att[L:R] * peak * 0.3)\n",
        "        if THRESHOLD!=None:\n",
        "            axs[i].axhline(y=THRESHOLD, color='r')\n",
        "\n",
        "    loss_normal_list = np.zeros(l)\n",
        "    cnt_normal = 0\n",
        "    loss_anomaly_list = np.zeros(l)\n",
        "    cnt_anomaly = 0\n",
        "    for i, loss in enumerate(xs):\n",
        "        if label[i] == 0:\n",
        "            loss_normal_list[cnt_normal] = loss\n",
        "            cnt_normal += 1\n",
        "        else:\n",
        "            loss_anomaly_list[cnt_anomaly] = loss\n",
        "            cnt_anomaly += 1\n",
        "    loss_normal_list = loss_normal_list[0:cnt_normal]\n",
        "    loss_anomaly_list = loss_anomaly_list[0:cnt_anomaly]\n",
        "\n",
        "    fig.savefig(FILENAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arOm-unBb0C-"
      },
      "source": [
        "def put_labels(distance, threshold):\n",
        "    xs = np.zeros_like(distance)\n",
        "    xs[distance > threshold] = 1\n",
        "    return xs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4NmgSuLp-Tm"
      },
      "source": [
        "window 방식으로 추론이 진행됐기 때문에, 처음 시작 부분과 데이터셋 중간에 시간이 연속되지 않는 부분을 0으로 채워주기 위한 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiO9VIffchbz"
      },
      "source": [
        "def fill_blank(check_ts, labels, total_ts):\n",
        "    def ts_generator():\n",
        "        for t in total_ts:\n",
        "            yield dateutil.parser.parse(t)\n",
        "\n",
        "    def label_generator():\n",
        "        for t, label in zip(check_ts, labels):\n",
        "            yield dateutil.parser.parse(t), label\n",
        "\n",
        "    g_ts = ts_generator()\n",
        "    g_label = label_generator()\n",
        "    final_labels = []\n",
        "\n",
        "    try:\n",
        "        current = next(g_ts)\n",
        "        ts_label, label = next(g_label)\n",
        "        while True:\n",
        "            if current > ts_label:\n",
        "                ts_label, label = next(g_label)\n",
        "                continue\n",
        "            elif current < ts_label:\n",
        "                final_labels.append(0)\n",
        "                current = next(g_ts)\n",
        "                continue\n",
        "            final_labels.append(label)\n",
        "            current = next(g_ts)\n",
        "            ts_label, label = next(g_label)\n",
        "    except StopIteration:\n",
        "        return np.array(final_labels, dtype=np.int8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXbjNLZb0Fh"
      },
      "source": [
        "TRAIN_DATASET = sorted([x for x in Path(\"./data/train/\").glob(\"*.csv\")])\n",
        "TEST_DATASET = sorted([x for x in Path(\"./data/test/\").glob(\"*.csv\")])\n",
        "VALIDATION_DATASET = sorted([x for x in Path(\"./data/validation/\").glob(\"*.csv\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoIujdUqb0H0"
      },
      "source": [
        "TIMESTAMP_FIELD = \"timestamp\"\n",
        "IDSTAMP_FIELD = 'id'\n",
        "ATTACK_FIELD = \"attack\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8vCtCU4b0KD"
      },
      "source": [
        "TRAIN_DF_RAW = dataframe_from_csvs(TRAIN_DATASET)\n",
        "VALIDATION_DF_RAW = dataframe_from_csvs(VALIDATION_DATASET)\n",
        "TEST_DF_RAW = dataframe_from_csvs(TEST_DATASET)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0HLyPVjmLD8"
      },
      "source": [
        "최종 모델에서는 33개의 Column을 선택하여 모델을 학습했습니다. 더 많은 Column을 포함해서 학습해 보았지만, public score 기준으로 성능이 낮게나와 최종 모델로 선정하지 않았습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99yuZ-O4b0MG"
      },
      "source": [
        "DROP_FIELD = [\"timestamp\", \"C01\", \"C02\", \"C03\", \"C04\", \"C06\", \"C07\", \"C08\", \"C09\", \"C10\", \"C11\", \"C13\", \"C17\",\n",
        "                \"C18\", \"C19\", \"C20\", \"C22\", \"C25\", \"C26\", \"C29\", \"C30\", \"C33\", \"C34\", \"C35\", \"C36\", \"C37\",\n",
        "                \"C38\", \"C39\", \"C41\", \"C42\", \"C44\", \"C45\", \"C46\", \"C48\", \"C49\", \"C50\", \"C52\", \"C53\", \"C55\",\n",
        "                \"C58\", \"C60\", \"C61\", \"C63\", \"C64\", \"C65\", \"C66\", \"C69\", \"C79\", \"C81\", \"C82\",\n",
        "                \"C83\", \"C84\", \"C85\", \"C86\"]\n",
        "\n",
        "VALID_COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop(DROP_FIELD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiShXKunznuq"
      },
      "source": [
        "TAG_MIN과 TAG_MAX는 학습 데이터셋에서 최솟값 최댓값을 얻은 결과입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgPV6PCVb0Oa"
      },
      "source": [
        "TAG_MIN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].min()\n",
        "TAG_MAX = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjxpUbhQnBrk"
      },
      "source": [
        "**hyperparameter 선정**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg8m5IQUcvQV"
      },
      "source": [
        "args = easydict.EasyDict({\n",
        "    \"batch_size\": 256, ## 배치 사이즈 설정  \n",
        "    \"device\": torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'), ## GPU 사용 여부 설정\n",
        "    \"input_size\": len(VALID_COLUMNS_IN_TRAIN_DATASET), ## 입력 차원 설정\n",
        "    \"output_size\": len(VALID_COLUMNS_IN_TRAIN_DATASET), ## 출력 차원 설정\n",
        "    \"window_size\" : 90, ## sequence Length\n",
        "    \"epochs\" : 256, ## epoch 사이즈 설정\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh50PJNjsze0"
      },
      "source": [
        "MODEL 경로명 설정 및 저장 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "himsxighcvOa"
      },
      "source": [
        "MODEL_NAME = './data/' +  '_WindowSize'+str(args.window_size) + '_Epochs' + str(args.epochs) +'_' + str(args.input_size) + 'Sensors'\n",
        "print(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdxuyOgdyehv"
      },
      "source": [
        "**Feature noise 제거**\n",
        "\n",
        "feature scaling이 완료된 데이터를 EWM을 적용해 Noise를 제거해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAl9WWTccvMb"
      },
      "source": [
        "TRAIN_DF = normalize(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MecnQk2QykGr"
      },
      "source": [
        "경로에 훈련된 model의 유무를 확인하고, 모델이 존재하면 훈련과정을 생략합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7PxZ6n3cvKA"
      },
      "source": [
        "filename = MODEL_NAME + '.model'\n",
        "if os.path.isfile(filename) is False:\n",
        "    HS_DATASET_TRAIN = HS_DATASET(TRAIN_DF_RAW[TIMESTAMP_FIELD], TRAIN_DF,  window_size=args.window_size, stride=1)\n",
        "    MODEL = model(args.input_size, args.window_size, )\n",
        "    MODEL.to(args.device)\n",
        "    MODEL.train()\n",
        "    BEST_MODEL, LOSS_HISTORY = train(HS_DATASET_TRAIN, MODEL, args.batch_size, args.epochs)\n",
        "    with open(filename, \"wb\") as f:\n",
        "        torch.save(MODEL, f)\n",
        "with open(filename, \"rb\") as f:\n",
        "    SAVED_MODEL = torch.load(f)\n",
        "    SAVED_MODEL.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNcaF3vDcvHz"
      },
      "source": [
        "VALIDATION_DF = normalize(VALIDATION_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()   \n",
        "HAI_DATASET_VALIDATION = HS_DATASET(VALIDATION_DF_RAW[TIMESTAMP_FIELD], VALIDATION_DF, window_size=args.window_size, attacks=VALIDATION_DF_RAW[ATTACK_FIELD])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIuCA-PscvFS"
      },
      "source": [
        "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_VALIDATION, SAVED_MODEL, args.batch_size)\n",
        "ATTACK_LABELS = put_labels(np.array(VALIDATION_DF_RAW[ATTACK_FIELD]), threshold=0.5)\n",
        "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)\n",
        "check_graph(ANOMALY_SCORE, CHECK_ATT, ATTACK_LABELS, piece=2, THRESHOLD=0.025, FILENAME=MODEL_NAME+'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-YOMCF9rpE3"
      },
      "source": [
        "THRESHOLD에 대한 f1 점수를 텍스트화해서 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chZSCzGAcvDE"
      },
      "source": [
        "filename = MODEL_NAME + '.txt'\n",
        "fp = open(filename,'w')\n",
        "# for문을 통해서 THRESHOLD 값들을 바꿔가며 가장 높게 TaR score가 나온 THRESHOLD을 선정했습니다.\n",
        "# THRESHOLD가 0.01이 TaR score가 가장 높게 나왔기 때문에 최종제출에는 THRESHOLD을 0.01로 설정했습니다.\n",
        "# 10초 중에 반 이상이 1일 경우 10초 모두를 1로 바꾸도록 만들었습니다.\n",
        "# 공격은 최소 60초 이상 지속된다고 가정을 하고, 구간의 시작이 0이나 1일때, 같은 값이 60초보다 적으면 공격이 아니라고(0이라고) 간주했습니다.\n",
        "\n",
        "for THRESHOLD in range(0.005,0.02,0.001):\n",
        "    LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
        "    ATTACK_LABELS = put_labels(np.array(VALIDATION_DF_RAW[ATTACK_FIELD]), threshold=0.5)\n",
        "    FINAL_LABELS = fill_blank(CHECK_TS, LABELS, np.array(VALIDATION_DF_RAW[TIMESTAMP_FIELD]))\n",
        "    sec = 10\n",
        "    for i in range(sec,len(FINAL_LABELS), 5):\n",
        "        start = i-(sec)\n",
        "        end = i\n",
        "        if list(FINAL_LABELS[start:end]).count(1) > (end-start)/2:\n",
        "            FINAL_LABELS[start:end] = np.array([1]*(end-start))\n",
        "    sec = 60\n",
        "    flag = False\n",
        "    start = 0\n",
        "    end = 0\n",
        "    for i in range(len(FINAL_LABELS)):\n",
        "        if flag == False and FINAL_LABELS[i] == 1:\n",
        "            flag = True\n",
        "            start = i\n",
        "        if flag == True and FINAL_LABELS[i] == 0:\n",
        "            end = i\n",
        "            if end-start < sec:\n",
        "                FINAL_LABELS[start:end] = np.array([0]*(end-start))\n",
        "            flag = False\n",
        "\n",
        "    TaPR = etapr.evaluate_haicon(anomalies=ATTACK_LABELS, predictions=FINAL_LABELS)\n",
        "    print(f\"THRESHOLD: {THRESHOLD:.4f} F1: {TaPR['f1']:.4f} (TaP: {TaPR['TaP']:.4f}, TaR: {TaPR['TaR']:.4f})\")\n",
        "    print(f\"# of detected anomalies: {len(TaPR['Detected_Anomalies'])}\")\n",
        "    fp.write(f\"THRESHOLD: {THRESHOLD:.4f} F1: {TaPR['f1']:.4f} (TaP: {TaPR['TaP']:.4f}, TaR: {TaPR['TaR']:.4f}) \\n\")\n",
        "    fp.write(f\"# of detected anomalies: {len(TaPR['Detected_Anomalies'])} \\n\")\n",
        "fp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WD8L0vpy3f6"
      },
      "source": [
        "#테스트 데이터셋 예측\n",
        "\n",
        "앞서 진행한 데이터 전처리를 동일하게 test data에도 적용합니다. \n",
        "\n",
        "또한, 학습 데이터셋과 검증 데이터셋을 이용해 만든 모델로 테스트 데이터셋 결과를 예측합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKS2pJoCcvAt"
      },
      "source": [
        "TEST_DF = normalize(TEST_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()\n",
        "HAI_DATASET_TEST = HS_DATASET(TEST_DF_RAW[TIMESTAMP_FIELD], TEST_DF,window_size=args.window_size, attacks=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5FBuU9Bcu-h"
      },
      "source": [
        "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_TEST, SAVED_MODEL, args.batch_size)\n",
        "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZwX0ZKtsZ3X"
      },
      "source": [
        "**최종 Threshold 선정**\n",
        "\n",
        "Threshold : 0.01로 설정하여 submission.csv파일 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89s8_3DCcu4H"
      },
      "source": [
        "THRESHOLD = 0.01\n",
        "LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
        "FINAL_LABELS = fill_blank(CHECK_TS, LABELS, np.array(TEST_DF_RAW[TIMESTAMP_FIELD]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZHi_T0gsB2o"
      },
      "source": [
        "# 데이터 후처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ho7e1MWr-lX"
      },
      "source": [
        "중간중간 noise와 같이 값이 튀는 것들이 있어, 이것들을 smoothing해주어 더 좋은 점수를 얻을 수 있었습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLRKm3P2dFTx"
      },
      "source": [
        "sec = 5\n",
        "for i in range(sec,len(FINAL_LABELS), 3):\n",
        "    start = i-(sec)\n",
        "    end = i\n",
        "    if list(FINAL_LABELS[start:end]).count(1) > (end-start)/2:\n",
        "        FINAL_LABELS[start:end] = np.array([1]*(end-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOCgiY1BsQYu"
      },
      "source": [
        "공격은 최소 60초 이상 지속된다고 가정을 하고, 구간의 시작이 0이나 1일때, 같은 값이 60초보다 적으면 공격이 아니라고(0이라고) 간주했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KLtE4GCdFRa"
      },
      "source": [
        "sec = 60\n",
        "flag = False\n",
        "start = 0\n",
        "end = 0\n",
        "for i in range(len(FINAL_LABELS)):\n",
        "    if flag == False and FINAL_LABELS[i] == 1:\n",
        "        flag = True\n",
        "        start = i\n",
        "    \n",
        "    if flag == True and FINAL_LABELS[i] == 0:\n",
        "        end = i\n",
        "        if end-start < sec:\n",
        "            FINAL_LABELS[start:end] = np.array([0]*(end-start))\n",
        "        flag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ0Ojh83t3u_"
      },
      "source": [
        "예측한 결과를 제출양식에 맞춰 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcosKoSxdFOi"
      },
      "source": [
        "submission = pd.read_csv('./data/sample_submission.csv')\n",
        "submission.index = submission['timestamp']\n",
        "submission.loc[TEST_DF_RAW[TIMESTAMP_FIELD],'attack'] = FINAL_LABELS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEueSC31t-YM"
      },
      "source": [
        "예측한 결과를 저장하여 제출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "729Gp8EodFL5"
      },
      "source": [
        "filename = MODEL_NAME + '_threshold_' + str(THRESHOLD) + '_submissionVer4.csv'\n",
        "submission.to_csv(filename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}